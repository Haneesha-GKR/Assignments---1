{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Headers \n",
    "headers = [\"Sentence\", \"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we read in the dataset\n",
    "dataset = pd.read_csv(\"C:/Users/haneesha/Anaconda3/textTrainData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Sentence  Sentiment\n",
      "0   So there is no way for me to plug it in here i...        0.0\n",
      "1                         Good case, Excellent value.        1.0\n",
      "2   Tied to charger for conversations lasting more...        0.0\n",
      "3                                   The mic is great.        1.0\n",
      "4   I have to jiggle the plug to get it to line up...        0.0\n",
      "5   If you have several dozen or several hundred c...        0.0\n",
      "6         If you are Razr owner...you must have this!        1.0\n",
      "7                 Needless to say, I wasted my money.        0.0\n",
      "8                    What a waste of money and time!.        0.0\n",
      "9   He was very impressed when going from the orig...        1.0\n",
      "10  If the two were seperated by a mere 5+ ft I st...        0.0\n",
      "11                           Very good quality though        1.0\n",
      "12  The design is very odd, as the ear clip is not...        0.0\n",
      "13  Highly recommend for any one who has a blue to...        1.0\n",
      "14                I advise EVERYONE DO NOT BE FOOLED!        0.0\n",
      "15                                      Works great!.        1.0\n",
      "16  It clicks into place in a way that makes you w...        0.0\n",
      "17  I went on Motorola's website and followed all ...        0.0\n",
      "18  I bought this to use with my Kindle Fire and a...        1.0\n",
      "19           The commercials are the most misleading.        0.0\n"
     ]
    }
   ],
   "source": [
    "# The above command returned a dataframe (with column and row names)\n",
    "print(dataset.iloc[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the headers to the loaded dataset\n",
    "dataset.columns = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haneesha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    " # Split dataset into train and test dataset\n",
    "train, test = train_test_split(dataset[headers[ : ]], train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence  Sentiment\n",
      "1267  I didn't know pulled pork could be soooo delic...        1.0\n",
      "757                       The kids are very cool too.          1.0\n",
      "86    The price was very good and with the free ship...        1.0\n",
      "1254  The goat taco didn't skimp on the meat and wow...        1.0\n",
      "861   Star Trek V The final Frontier is the worst in...        0.0\n"
     ]
    }
   ],
   "source": [
    "print(train [0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need a function that will split the text based upon sentiment\n",
    "def get_text(sent, score):\n",
    "  # Join together the text in the reviews for a particular sentiment.\n",
    "  # We lowercase to avoid \"Not\" and \"not\" being seen as different words, for example.\n",
    "   \n",
    "    s = \"\"\n",
    "    for index,row in sent.iterrows():\n",
    "        if row['Sentiment'] == score:\n",
    "            s = s + row['Sentence'].lower()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We also need a function that will count word frequency for each sample\n",
    "def count_text(text):\n",
    "  # Split text into words based on whitespace.  Simple but effective.\n",
    "  words = re.split(\"\\s+\", text)\n",
    "  # Count up the occurence of each word.\n",
    "  return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we will capture the negative and positive samples in the training set.\n",
    "# We will create two large strings, one of all text from positive reviews and one from the negatives\n",
    "# We will then use these to create the word counts\n",
    "# This will make the computations of the probabilities easier\n",
    "\n",
    "# This will take a few minutes and use up some memory!\n",
    "\n",
    "negative_train_text = get_text(train, 0)\n",
    "positive_train_text = get_text(train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didn't know pulled pork could be soooo delicious.the kids are very cool too.  the price was very g\n"
     ]
    }
   ],
   "source": [
    "print(positive_train_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we generate the word counts for each sentiment\n",
    "negative_counts = count_text(negative_train_text)\n",
    "# Generate word counts for positive tone.\n",
    "positive_counts = count_text(positive_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star trek v the final frontier is the worst in the series.  the food was terrible.the burger had abs\n"
     ]
    }
   ],
   "source": [
    "print(negative_train_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need this function to calculate a count of a given classification\n",
    "def get_y_count(score):\n",
    "  # Compute the count of each classification occuring in the data.\n",
    "  # return len([r for r in reviews if r[1] == str(score)])\n",
    "    c = 0\n",
    "    for index,row in train.iterrows():\n",
    "        if row['Sentiment'] == score:\n",
    "            c = c + 1\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need these counts to use for smoothing when computing the prediction.\n",
    "positive_sentence_count = get_y_count(1)\n",
    "negative_sentence_count = get_y_count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the class probabilities (we saw them in the formula as P(y)).\n",
    "prob_positive = positive_sentence_count / len(train)\n",
    "prob_negative = negative_sentence_count / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5260461144321094\n"
     ]
    }
   ],
   "source": [
    "print(prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finallt, we create a function that will, given a text example, allow us to calculate the probability\n",
    "# of a positive or negative review\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "  prediction = 1\n",
    "  text_counts = Counter(re.split(\"\\s+\", text))\n",
    "  for word in text_counts:\n",
    "      # For every word in the text, we get the number of times that word occured in the reviews for a given class, add 1 to smooth the value, and divide by the total number of words in the class (plus the class_count to also smooth the denominator).\n",
    "      # Smoothing ensures that we don't multiply the prediction by 0 if the word didn't exist in the training data.\n",
    "      # We also smooth the denominator counts to keep things even.\n",
    "      prediction *=  text_counts.get(word) * ((counts.get(word, 0) + 1) / (sum(counts.values()) + class_count))\n",
    "  # Now we multiply by the probability of the class existing in the documents.\n",
    "  return prediction * class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative prediction: 1.3394702708964042e-30\n",
      "Positive prediction: 1.6878267532391027e-32\n"
     ]
    }
   ],
   "source": [
    "print(\"Negative prediction: {0}\".format(make_class_prediction(train.iloc[0,0], negative_counts, prob_negative, negative_sentence_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(train.iloc[0,0], positive_counts, prob_positive, positive_sentence_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we will create a function that will actually make the prediction\n",
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities.\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_sentence_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_sentence_count)\n",
    "\n",
    "    # We assign a classification based on which probability is greater.\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(make_decision(train.iloc[0,0], make_class_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we make predictions on the test data. Since it is a large set, we will simply select 200 movies.\n",
    "predictions = [make_decision(row['Sentence'], make_class_prediction) for index,row in test[200:600].iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We check the accuracy. Note that when we pull the column out of the data frame, we need to convert it to a list\n",
    "# to compare with the predictions\n",
    "\n",
    "actual = test['Sentiment'].tolist()\n",
    "\n",
    "actual = actual[200:600]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5033\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(1 for i in range(len(predictions)) if predictions[i] == actual[i]) / float(len(predictions))\n",
    "print(\"{0:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
